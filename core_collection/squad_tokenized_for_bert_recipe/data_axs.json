 {
    "_parent_entries": [ [ "^", "byname", "python_script" ] ],
    "_producer_rules": [
        [ [ "tokenized", "squad_v1_1" ], [["run"]], {} ]
    ],

    "dataset_max_seq_length": 384,
    "dataset_max_query_length": 64,
    "dataset_doc_stride": 128,

    "tokenized_squad_files_prefix": "tokenized_squad_v1.1",

    "return_saved_record_entry": false,
    "return_this_entry": [ "^^", "execute", [[
        [ "get_kernel" ],
        [ "work_collection" ],
        [ "attached_entry", [ ["^^", "substitute", "tokenized_squad_v1_1_msl_#{dataset_max_seq_length}#"] , ["^^", "substitute", {
            "_parent_entries": [ "AS^IS", [ "^", "byname", "base_experiment" ] ],
            "tags": ["tokenized", "squad_v1_1"],
            "dataset_max_seq_length": "#{dataset_max_seq_length}#",
            "files_prefix": "#{tokenized_squad_files_prefix}#",
            "file_name": "#{tokenized_squad_files_prefix}#.pickled"
         } ] ] ],
         [ "save" ]
    ]] ],

    "tokenized_squad_dirname": [ "^^", "execute", [[
        [ "get", "return_this_entry" ],
        [ "get_path" ],
        0,
        [ "func", "os.path.dirname" ]
    ]] ],
    "tokenized_squad_dir": ["^^", "substitute", "#{tokenized_squad_dirname}#/" ],

    "tensorflow_query": ["python_package", "package_name=tensorflow"],
    "absl_query": ["python_package", "package_name=absl-py"],
    "transformers_query": ["python_package", "package_name=transformers"],

    "python_deps": [
        [ "^^", "python_sync_pip_package", [[ "^^", "get", "absl_query" ]] ],
        [ "^^", "python_sync_pip_package", [[ "^^", "get", "tensorflow_query" ]] ],
        [ "^^", "python_sync_pip_package", [[ "^^", "get", "transformers_query" ]] ]
    ],
    "mlperf_inference_git_entry": [ "^", "byquery", "git_repo,repo_name=mlperf_inference_git" ],

    "mlperf_inference_path": [ "^^", "execute", [[
        [ "get", "mlperf_inference_git_entry" ],
        [ "get_path" ]
    ]], {}, ["mlperf_inference_git_entry"] ],

    "squad_dataset_query":[ "downloaded", "squad_original" ],
    "squad_dataset_entry": [ "^", "byquery", [[ "^^", "get", "squad_dataset_query" ]], {}, ["squad_dataset_query"] ],
    "squad_dataset_original_path": [ "^^", "execute", [[
        [ "get", "squad_dataset_entry" ],
        [ "get_path" ]
    ]] ],

    "squad_tokenization_vocab_query":[ "downloaded", "tokenization", "vocab_for_bert" ],
    "squad_tokenization_vocab_entry": [ "^", "byquery", [[ "^^", "get", "squad_tokenization_vocab_query" ]], {}, ["squad_tokenization_vocab_query"] ],
    "squad_tokenization_vocab_path": [ "^^", "execute", [[
        [ "get", "squad_tokenization_vocab_entry" ],
        [ "get_path" ]
    ]] ],
    "rel_script_path": "tokenize_and_pack.py",
    "script_extra_params": [ "^^", "substitute", "\"#{squad_dataset_original_path}#\" \"#{squad_tokenization_vocab_path}#\" \"#{tokenized_squad_dir}#\" \"#{tokenized_squad_files_prefix}#\" #{dataset_max_seq_length}# #{dataset_max_query_length}# #{dataset_doc_stride}# \"#{mlperf_inference_path}#\"" ]
}
